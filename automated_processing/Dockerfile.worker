# Dockerfile for Distributed Processing Workers
# This runs Celery workers for automated batch processing
# Located in: automated_processing/Dockerfile.worker

# Stage 1: Builder - Install all dependencies
FROM python:3.11-slim AS builder

# Install build tools for compiling Python C extensions
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /build

# Copy requirements from automated_processing directory
COPY automated_processing/requirements.txt ./

# Install worker dependencies
RUN pip install --no-cache-dir --user \
    -r requirements.txt \
    sqlglot==20.11.0 \
    boto3==1.34.11 \
    s3fs==2023.12.0

# Stage 2: Production image
FROM python:3.11-slim

# Install Redis CLI for health checks (optional but useful)
RUN apt-get update && apt-get install -y \
    redis-tools \
    && rm -rf /var/lib/apt/lists/*

# Create worker user for security
RUN useradd -m -u 1000 worker

# Copy Python packages from builder
COPY --from=builder /root/.local /home/worker/.local

# Set working directory to automated_processing
WORKDIR /app/automated_processing

# Copy the automated_processing directory and parent directory files
COPY --chown=worker:worker automated_processing /app/automated_processing
COPY --chown=worker:worker apis /app/apis
COPY --chown=worker:worker sqlglot /app/sqlglot
COPY --chown=worker:worker guardrail /app/guardrail

# Environment setup
ENV PYTHONPATH=/app:/app/automated_processing:$PYTHONPATH
ENV PATH=/home/worker/.local/bin:$PATH
ENV PYTHONUNBUFFERED=1

# Redis connection settings (can be overridden)
ENV CELERY_BROKER_URL=redis://redis:6379/0
ENV CELERY_RESULT_BACKEND=redis://redis:6379/0

# Create directories for outputs
RUN mkdir -p /app/results /app/logs /app/iceberg_warehouse && \
    chown -R worker:worker /app

# Make start script executable
RUN chmod +x /app/automated_processing/start_worker.sh

# Switch to worker user
USER worker

# Health check - verify Celery can connect to Redis
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD celery -A worker.celery inspect ping || exit 1

# Use the start_worker.sh script but modify for container environment
# In container, we don't need to start Redis (it's a separate service)
# So we use the Celery command directly from the script
CMD ["celery", "-A", "worker.celery", "worker", \
     "--loglevel=info", \
     "--pool=prefork", \
     "--autoscale=8,1", \
     "-Q", "processing_queue"]